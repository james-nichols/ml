{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data leakage solution - Expedia Kaggle challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37670293, 24)\n",
      "(2528243, 22)\n",
      "grouped ['user_location_city', 'orig_destination_distance']\n",
      "grouped ['srch_destination_id', 'hotel_country', 'hotel_market']\n",
      "grouped ['srch_destination_id']\n",
      "grouped ['hotel_country']\n",
      "That took 3082.7677631378174 s:\n",
      "173.98987698554993 s for load,\n",
      "874.5405080318451s for dictionary build part,\n",
      "2034.2373881340027 for applying to test set \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5, 37, 55, 11, 22],\n",
       "       [ 5, 91, 41, 48, 64],\n",
       "       [91,  0, 31, 96, 91],\n",
       "       ..., \n",
       "       [54,  1, 45, 79, 24],\n",
       "       [50, 47, 43, 15, 32],\n",
       "       [12, 36, 81, 57, 62]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load = time.time()\n",
    "\n",
    "# Read the Data\n",
    "train = pd.read_csv(\"./train.csv\")#, nrows = 10000)\n",
    "target = train['hotel_cluster']\n",
    "test = pd.read_csv(\"./test.csv\")#, nrows = 1000)\n",
    "\n",
    "feat_names = test.columns.values\n",
    "\n",
    "dest = pd.read_csv(\"./destinations.csv\")\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "train.head()\n",
    "\n",
    "num_guesses = 5\n",
    "\n",
    "\n",
    "\n",
    "grp_feat_list = [['user_location_city', 'orig_destination_distance'],\n",
    "                 ['srch_destination_id', 'hotel_country', 'hotel_market'],\n",
    "                 ['srch_destination_id'],\n",
    "                 ['hotel_country']]\n",
    "grp_scoring = [[1, 1], # These are the scores for non-bookings vs bookings\n",
    "               [3, 20],\n",
    "               [3, 20],\n",
    "               [1, 6]]\n",
    "\n",
    "# Create a new score column... makes some things easier later...\n",
    "train['score'] = 1\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# We need to include the base aggregating case:\n",
    "import copy\n",
    "grps = []\n",
    "#for fl in grp_feat_list:\n",
    "for i in range(len(grp_feat_list)):\n",
    "    fl = grp_feat_list[i]\n",
    "    fl_hc = copy.copy(fl)\n",
    "    fl_hc.append('hotel_cluster')\n",
    "    \n",
    "    # Assign appropriate scores to bookings vs non-bookings\n",
    "    train.loc[train['is_booking'] == 0, 'score'] = grp_scoring[i][0]\n",
    "    train.loc[train['is_booking'] == 1, 'score'] = grp_scoring[i][1]\n",
    "    \n",
    "    # Sum up the score for each unique combo in the feature_list + hotel_cluster,\n",
    "    # then sort the values, then sort by the values, and regroup in to feature clusters\n",
    "    score = train.groupby(fl_hc).sum()['score'].sort_values(ascending=False).sortlevel(level=range(len(fl)), sort_remaining=False)\n",
    "    \n",
    "    # Now the rest of the magic: group and get the top 5 scores for each combo,\n",
    "    # then groupby and make that in to a list (that's why there's two groupby calls...)\n",
    "    # NB the .apply(list) call takes the majority of the computing time, it's a python inner loop...\n",
    "    #top_scoring = score.reset_index().groupby(fl_hc).head(num_guesses).groupby(fl)['hotel_cluster'].apply(list)\n",
    "    \n",
    "    # oh wait nevermind, top 5 (using groupby(...).head(num_guesses)) doesn't work... just list:\n",
    "    top_scoring = score.reset_index().groupby(fl)['hotel_cluster'].apply(list)\n",
    "   \n",
    "    grps.append(top_scoring.to_dict())\n",
    "    \n",
    "    print(\"grouped \" + str(fl))\n",
    "\n",
    "# Now need to just do the top 5 hotel_clusters...\n",
    "\n",
    "# Assign appropriate scores to bookings vs non-bookings\n",
    "train.loc[train['is_booking'] == 0, 'score'] = 1\n",
    "train.loc[train['is_booking'] == 1, 'score'] = 1\n",
    "\n",
    "top_h_c = train.groupby(['hotel_cluster'])['score'].sum().sort_values(ascending=False).index\n",
    "\n",
    "mid = time.time()\n",
    "# Now the tricky bit to do fast: selecting the appropriate combinations of predictors and hotel_clusters...\n",
    "#\n",
    "# First a slow row by row solution\n",
    "#\n",
    "\n",
    "# This is all the guesses for the test data set\n",
    "guesses = np.zeros([test.shape[0], num_guesses], dtype=np.int32)\n",
    "\n",
    "for r_i, r in test.iterrows():\n",
    "    num_filled = 0\n",
    "    \n",
    "    # Go through each group combo to see if it exists in the training set\n",
    "    for i in range(len(grp_feat_list)):\n",
    "\n",
    "        # This is a tuple of the relevant features, e.g.\n",
    "        # (user_location_city, orig_destination_distance) = (3, 5539.06)\n",
    "        # THIS IS A TUPLE to be able to select using the .loc() \n",
    "        # function of the grouped data frames.\n",
    "        \n",
    "        chooser = tuple(r[grp_feat_list[i]].values)\n",
    "        try:\n",
    "            candidates = grps[i][chooser]#.sort_values(ascending = False)\n",
    "            \n",
    "            # Remove duplicates...\n",
    "            \n",
    "            # Select only as many as we can fill, and at most 5 (YES, we do it this\n",
    "            # way around and potentially exhaust the candidates when we look at uniqueness)\n",
    "            fillable = min(len(candidates), num_guesses-num_filled)\n",
    "            \n",
    "            guesses[r_i, num_filled:num_filled+fillable] = candidates[:fillable]\n",
    "            num_filled = fillable + num_filled\n",
    "            \n",
    "            if num_filled == num_guesses:\n",
    "                break\n",
    "            \n",
    "        except KeyError:\n",
    "            # We are here because the \"chooser\" tuple was not found in the combo from \n",
    "            # the training set, so we merely go on to the next tuple of features in grp_feat_list\n",
    "            pass\n",
    "\n",
    "    # Now we fill in any remaining guesses with just the top guesses:\n",
    "    fillable = min(len(top_h_c), num_guesses-num_filled)\n",
    "    guesses[r_i, num_filled:num_filled+fillable] = top_h_c[:fillable]\n",
    "    \n",
    "print(\"That took \" + str(time.time() - load) + \" s:\\n\" + str(start - load) + \" s for load,\\n\" + str(mid-start) \\\n",
    "      + \"s for dictionary build part,\\n\" + str(time.time() - mid) + \" for applying to test set \")\n",
    "guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 37, 55, 11, 22],\n",
       "       [ 5, 91, 41, 48, 64],\n",
       "       [91,  0, 31, 96, 91],\n",
       "       [ 1,  1, 45, 79, 24],\n",
       "       [50, 51, 91,  2, 42],\n",
       "       [91, 42, 28, 95, 48],\n",
       "       [95, 21,  2, 33, 98],\n",
       "       [95, 91, 18, 98, 68],\n",
       "       [88,  1, 45, 79, 24],\n",
       "       [55, 32, 10, 34, 50]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 0 time: 0.0010449886322021484\n",
      "0\n",
      "> <ipython-input-4-8bb3f5024fad>(12)<module>()\n",
      "-> for r_i, r in test.iterrows():\n",
      "(Pdb) candidates\n",
      "*** NameError: name 'candidates' is not defined\n",
      "(Pdb) chooser\n",
      "(204,)\n",
      "(Pdb) p i\n",
      "3\n",
      "(Pdb) h_c_candidates\n",
      "*** NameError: name 'h_c_candidates' is not defined\n",
      "(Pdb) 1\n",
      "1\n",
      "(Pdb) q\n"
     ]
    }
   ],
   "source": [
    "# Now the tricky bit to do fast: selecting the appropriate combinations of predictors and hotel_clusters...\n",
    "#\n",
    "# First a slow row by row solution\n",
    "#\n",
    "import time\n",
    "\n",
    "# This is all the guesses for the test data set\n",
    "guesses = np.zeros([test.shape[0], num_guesses], dtype=np.int32)\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "for r_i, r in test.iterrows():\n",
    "    if r_i % 100 == 0:\n",
    "        print(\"row: \" + str(r_i) + \" time: \" + str(time.time() - t))\n",
    "        t = time.time()\n",
    "    num_filled = 0\n",
    "    \n",
    "    # Go through each group combo to see if it exists in the training set\n",
    "    for i in range(len(grp_feat_list)):\n",
    "\n",
    "        # This is a tuple of the relevant features, e.g.\n",
    "        # (user_location_city, orig_destination_distance) = (3, 5539.06)\n",
    "        # THIS IS A TUPLE to be able to select using the .loc() \n",
    "        # function of the grouped data frames.\n",
    "        \n",
    "        chooser = tuple(r[grp_feat_list[i]].values)\n",
    "        try:\n",
    "            # Selects the scores matching the features of our current row\n",
    "            # Also sorts by search score. THIS IS THE SLOWEST PART OF THE ROUTINE\n",
    "            # PROBABLY DUE TO SORT...\n",
    "            if chooser: # True if the chooser exists\n",
    "                candidates = grps[i][chooser]#.sort_values(ascending = False)\n",
    "            else:\n",
    "                candidates = grps[i]#.sort_values(ascending = False)\n",
    "            \n",
    "            # This gets the top 5 (max) hotel_cluster candidates from the sorted series\n",
    "            h_c_candidates = candidates[:num_guesses].index.get_level_values('hotel_cluster')\n",
    "            \n",
    "            # Remove duplicates (for some reason can't to inplace=True)\n",
    "            h_c_candidates = h_c_candidates.drop(guesses[r_i, :num_filled], errors='ignore')\n",
    "            \n",
    "            # Select only as many as we can fill, and at most 5 (YES, we do it this\n",
    "            # way around and potentially exhaust the candidates when we look at uniqueness)\n",
    "            fillable = min(len(h_c_candidates), num_guesses-num_filled)\n",
    "            \n",
    "            guesses[r_i, num_filled:num_filled+fillable] = h_c_candidates[:fillable].values\n",
    "            num_filled = fillable + num_filled\n",
    "            \n",
    "            if num_filled == num_guesses:\n",
    "                break\n",
    "            \n",
    "        except KeyError:\n",
    "            # We are here because the \"chooser\" tuple was not found in the combo from \n",
    "            # the training set, so we merely go on to the next tuple of features in grp_feat_list\n",
    "            pass\n",
    "\n",
    "    if num_filled < num_guesses:\n",
    "        # This only occures if there's an error..\n",
    "        print(r_i)\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 37, 55, 11, 22],\n",
       "       [ 5, 25, 64, 11,  8],\n",
       "       [91,  0, 31, 96, 77],\n",
       "       ..., \n",
       "       [ 0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses\n",
    "\n",
    "# Now some half baked attempt at a \"fast\" solution?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                date_time  site_name  posa_continent  user_location_country  \\\n",
      "8279  2014-10-02 13:28:49         10               0                    182   \n",
      "8281  2014-10-24 19:35:53         10               0                    182   \n",
      "\n",
      "      user_location_region  user_location_city  orig_destination_distance  \\\n",
      "8279                   199                   3                   577.1299   \n",
      "8281                   199                   3                   577.1299   \n",
      "\n",
      "      user_id  is_mobile  is_package      ...        srch_children_cnt  \\\n",
      "8279    49731          0           0      ...                        0   \n",
      "8281    49731          0           0      ...                        0   \n",
      "\n",
      "     srch_rm_cnt srch_destination_id  srch_destination_type_id  is_booking  \\\n",
      "8279           1               41452                         1           0   \n",
      "8281           1               41452                         1           0   \n",
      "\n",
      "      cnt  hotel_continent  hotel_country  hotel_market  hotel_cluster  \n",
      "8279    1                4            196          1992             67  \n",
      "8281    1                4            196          1992             67  \n",
      "\n",
      "[2 rows x 24 columns]\n",
      "date_time                   2\n",
      "site_name                   2\n",
      "posa_continent              2\n",
      "user_location_country       2\n",
      "user_location_region        2\n",
      "user_id                     2\n",
      "is_mobile                   2\n",
      "is_package                  2\n",
      "channel                     2\n",
      "srch_ci                     2\n",
      "srch_co                     2\n",
      "srch_adults_cnt             2\n",
      "srch_children_cnt           2\n",
      "srch_rm_cnt                 2\n",
      "srch_destination_id         2\n",
      "srch_destination_type_id    2\n",
      "is_booking                  2\n",
      "cnt                         2\n",
      "hotel_continent             2\n",
      "hotel_country               2\n",
      "hotel_market                2\n",
      "hotel_cluster               2\n",
      "Name: (3, 577.1299), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "grp = train.groupby(['user_location_city', 'orig_destination_distance']).count()\n",
    "\n",
    "print(train[(train['user_location_city'] == grp.index[1][0]).values & (train['orig_destination_distance'] == grp.index[1][1]).values])\n",
    "print(grp.iloc[1])\n",
    "#train['user_location_city'] == grp.index[1][0]\n",
    "#print(train['orig_destination_distance'] == grp.index[1][1])\n",
    "#train[train['user_location_city'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "$\\int_{-\\infty}^{\\infty} f(x) \\, \\mathrm{d}x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
