{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gradient Boosting - Expedia Kaggle challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing      import LabelEncoder\n",
    "from sklearn.preprocessing      import OneHotEncoder\n",
    "from sklearn.cross_validation   import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# This gives us the \"Mean average precision\" function\n",
    "import ml_metrics as metrics \n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import ml_utilities\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date_time', 'srch_ci', 'srch_co'], dtype='object')\n",
      "Index(['site_name', 'posa_continent', 'user_location_country',\n",
      "       'user_location_region', 'user_location_city',\n",
      "       'orig_destination_distance', 'user_id', 'is_mobile', 'is_package',\n",
      "       'channel', 'srch_adults_cnt', 'srch_children_cnt', 'srch_rm_cnt',\n",
      "       'srch_destination_id', 'srch_destination_type_id', 'is_booking', 'cnt',\n",
      "       'hotel_continent', 'hotel_country', 'hotel_market', 'date_time_day',\n",
      "       'date_time_month', 'date_time_year', 'srch_ci_day', 'srch_ci_month',\n",
      "       'srch_ci_year', 'srch_co_day', 'srch_co_month', 'srch_co_year'],\n",
      "      dtype='object')\n",
      "training set shape: 10000x29, test set shape: 1000x28\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./train.csv\", nrows = 10000)\n",
    "target = train['hotel_cluster']\n",
    "train = train.drop(['hotel_cluster'],axis=1)\n",
    "test = pd.read_csv(\"./test.csv\", nrows = 1000)\n",
    "\n",
    "feat_names = test.columns.values\n",
    "dest = pd.read_csv(\"./destinations.csv\")\n",
    "\n",
    "obj_feat = train.select_dtypes(include=[object]).keys()\n",
    "\n",
    "# We convert the date columns in to columns indicating day / month / year\n",
    "for col in obj_feat:\n",
    "\n",
    "    tr_date_series = pd.DatetimeIndex(train[col])\n",
    "    te_date_series = pd.DatetimeIndex(test[col])\n",
    "\n",
    "    train[col + '_day'] = tr_date_series.day\n",
    "    test[col + '_day'] = te_date_series.day\n",
    "    train[col + '_month'] = tr_date_series.month\n",
    "    test[col + '_month'] = te_date_series.month\n",
    "    train[col + '_year'] = tr_date_series.year\n",
    "    test[col + '_year'] = te_date_series.year\n",
    "\n",
    "    train = train.drop([col], axis=1)\n",
    "    test = test.drop([col], axis=1)\n",
    "\n",
    "train.head()\n",
    "print(obj_feat)\n",
    "print(train.keys())\n",
    "print(\"training set shape: {0}x{1}, test set shape: {2}x{3}\".format(train.shape[0], train.shape[1],test.shape[0], test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = ml_utilities.randomised_imputer(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without decay ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until valid error hasn't decreased in 20 rounds.\n",
      "[0]\ttrain-map:0.991753\tvalid-map:0.993766\n",
      "[1]\ttrain-map:0.991724\tvalid-map:0.994342\n",
      "[2]\ttrain-map:0.992096\tvalid-map:0.994519\n",
      "[3]\ttrain-map:0.992900\tvalid-map:0.994409\n",
      "[4]\ttrain-map:0.993030\tvalid-map:0.994252\n",
      "[5]\ttrain-map:0.993338\tvalid-map:0.994339\n",
      "[6]\ttrain-map:0.992913\tvalid-map:0.993285\n",
      "[7]\ttrain-map:0.993095\tvalid-map:0.993722\n",
      "[8]\ttrain-map:0.992947\tvalid-map:0.993613\n",
      "[9]\ttrain-map:0.993071\tvalid-map:0.993470\n",
      "[10]\ttrain-map:0.992879\tvalid-map:0.993766\n",
      "[11]\ttrain-map:0.993035\tvalid-map:0.993902\n",
      "[12]\ttrain-map:0.992873\tvalid-map:0.993878\n",
      "[13]\ttrain-map:0.993129\tvalid-map:0.993875\n",
      "[14]\ttrain-map:0.993171\tvalid-map:0.993864\n",
      "[15]\ttrain-map:0.993350\tvalid-map:0.994135\n",
      "[16]\ttrain-map:0.993337\tvalid-map:0.994395\n",
      "[17]\ttrain-map:0.993332\tvalid-map:0.994410\n",
      "[18]\ttrain-map:0.993098\tvalid-map:0.994068\n",
      "[19]\ttrain-map:0.993184\tvalid-map:0.994064\n",
      "[20]\ttrain-map:0.993320\tvalid-map:0.994060\n",
      "[21]\ttrain-map:0.993286\tvalid-map:0.994061\n",
      "[22]\ttrain-map:0.993290\tvalid-map:0.994027\n",
      "[23]\ttrain-map:0.993160\tvalid-map:0.994061\n",
      "[24]\ttrain-map:0.993304\tvalid-map:0.994240\n",
      "[25]\ttrain-map:0.993329\tvalid-map:0.994282\n",
      "[26]\ttrain-map:0.993526\tvalid-map:0.994558\n",
      "Stopping. Best iteration:\n",
      "[6]\ttrain-map:0.992913\tvalid-map:0.993285\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of classes 100, 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-366ebeed5341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nWithout decay ...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbest_model_nd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mdte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-71cc16ced9b6>\u001b[0m in \u001b[0;36mdo_train\u001b[0;34m(X, Y, params, verbose)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mtotal_rounds\u001b[0m   \u001b[0;34m+=\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mcv_score\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         raise ValueError(\"y_true and y_pred have different number of classes \"\n\u001b[0;32m-> 1565\u001b[0;31m                          \"%d, %d\" % (T.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[0;31m# Renormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of classes 100, 2"
     ]
    }
   ],
   "source": [
    "Y = target.values  #train.target.values.astype(np.int32)\n",
    "X = train.values      #train[ [ \"VAR_0001\", \"VAR_0005\", \"VAR_0006\", \"VAR_0226\"] ].values\n",
    "\n",
    "params = {\n",
    "    \"max_depth\"             : 5, \n",
    "    \"eta\"                   : 0.1,\n",
    "    \"min_eta\"               : 0.00001,\n",
    "    \"eta_decay\"             : 0.5,\n",
    "    \"max_fails\"             : 3,\n",
    "    \"early_stopping_rounds\" : 20,\n",
    "    \"objective\"             : 'rank:pairwise',\n",
    "    \"subsample\"             : 0.8, \n",
    "    \"colsample_bytree\"      : 1.0,\n",
    "    \"n_jobs\"                : -1,\n",
    "    \"n_estimators\"          : 5000, \n",
    "    \"silent\"                : 1,\n",
    "    \"gamma\"                 : 0.1,\n",
    "    \"min_child_weight\"      : 1.1\n",
    "    }\n",
    "\n",
    "print(\"\\nWithout decay ...\\n\")\n",
    "best_model_nd = do_train(X, Y, params)\n",
    "\n",
    "dte = xgb.DMatrix(te.values)\n",
    "te_pred_nd = best_model_nd.predict(dte, ntree_limit=best_model_nd.best_iteration+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_name = \"pred_cv_{0}_{1}_{2}_{3}_{4}\".format(params[\"eta\"], params[\"n_estimators\"], \n",
    "                                                params[\"max_depth\"], params[\"gamma\"], params[\"min_child_weight\"])\n",
    "\n",
    "# Save results\n",
    "predictions_file = open(output_name + \".csv\", \"w\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"ID\", \"PredictedProb\"])\n",
    "open_file_object.writerows(zip(IDs, te_pred_nd))\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training routine - execute this cell before the others to make it all work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_mapk(target, predictions):\n",
    "    \n",
    "    targ = [[l] for l in target]\n",
    "    pred = [[p] for p in predictions]\n",
    "    metrics.mapk(targ, pred, k=5)\n",
    "\n",
    "def do_train(X, Y, params, verbose=False):\n",
    "    ''' Trains a model with inputs X against predictor variable Y, with CV '''\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    cv_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    split = StratifiedKFold(Y, 5, shuffle=True )\n",
    "    fold = 0\n",
    "    \n",
    "    for train_index, cv_index in split:\n",
    "    \n",
    "        fold = fold + 1\n",
    "                    \n",
    "        X_train, X_valid    = X[train_index,:], X[cv_index,:]\n",
    "        y_train, y_valid    = Y[train_index],   Y[cv_index]\n",
    "    \n",
    "        num_round       = params[\"n_estimators\"]\n",
    "        eta             = params[\"eta\"]\n",
    "        min_eta         = params[\"min_eta\"]\n",
    "        eta_decay       = params[\"eta_decay\"]\n",
    "        early_stop      = params[\"early_stopping_rounds\"]\n",
    "        max_fails       = params[\"max_fails\"]\n",
    "        \n",
    "        params_copy     = dict(params)\n",
    "        \n",
    "        dtrain          = xgb.DMatrix( X_train, label=y_train ) \n",
    "        dvalid          = xgb.DMatrix( X_valid, label=y_valid )  \n",
    "    \n",
    "        total_rounds        = 0\n",
    "        best_rounds         = 0\n",
    "        pvalid              = None\n",
    "        model               = None\n",
    "        best_train_score    = None\n",
    "        best_cv_score       = None\n",
    "        fail_count          = 0\n",
    "        best_rounds         = 0\n",
    "        best_model          = None\n",
    "        \n",
    "        while eta >= min_eta:           \n",
    "            \n",
    "            model        = xgb.train( params_copy.items(), \n",
    "                                      dtrain, \n",
    "                                      num_round, \n",
    "                                      [(dtrain, 'train'), (dvalid,'valid')], \n",
    "                                      early_stopping_rounds=early_stop)\n",
    "                #,\n",
    "                #                      feval=evallogloss )\n",
    "    \n",
    "            rounds          = model.best_iteration + 1\n",
    "            total_rounds   += rounds\n",
    "            \n",
    "            train_score = log_loss( y_train, model.predict(dtrain, ntree_limit=rounds) )\n",
    "            cv_score    = log_loss( y_valid, model.predict(dvalid, ntree_limit=rounds) )\n",
    "    \n",
    "            if best_cv_score is None or cv_score > best_cv_score:\n",
    "                fail_count = 0\n",
    "                best_train_score = train_score\n",
    "                best_cv_score    = cv_score\n",
    "                best_rounds      = rounds\n",
    "                best_model       = model\n",
    "\n",
    "                ptrain           = best_model.predict(dtrain, ntree_limit=rounds, output_margin=True)\n",
    "                pvalid           = best_model.predict(dvalid, ntree_limit=rounds, output_margin=True)\n",
    "                \n",
    "                dtrain.set_base_margin(ptrain)\n",
    "                dvalid.set_base_margin(pvalid)\n",
    "            else:\n",
    "                fail_count += 1\n",
    "\n",
    "                if fail_count >= max_fails:\n",
    "                    break\n",
    "    \n",
    "            eta                 = eta_decay * eta\n",
    "            params_copy[\"eta\"]  = eta\n",
    "    \n",
    "        train_scores.append(best_train_score)\n",
    "        cv_scores.append(best_cv_score)\n",
    "\n",
    "        print(\"Fold [%2d] %9.6f : %9.6f\" % ( fold, best_train_score, best_cv_score ))\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Mean      %9.6f : %9.6f\" % ( np.mean(train_scores), np.mean(cv_scores) ) )\n",
    "    print(\"Stds      %9.6f : %9.6f\" % ( np.std(train_scores),  np.std(cv_scores) ) )\n",
    "    print(\"-------------------------------\")\n",
    "      \n",
    "    return best_model\n",
    "\n",
    "# ----------------------------f----------------------------------------------------\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
