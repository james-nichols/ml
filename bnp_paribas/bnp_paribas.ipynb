{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math, csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "from ml_utilities import *\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2 v3        v4         v5        v6        v7        v8  \\\n",
       "0  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895  0.012941   \n",
       "1       NaN       NaN  C       NaN   9.191265       NaN       NaN  2.301630   \n",
       "2  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571  0.019645   \n",
       "3  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549  0.171947   \n",
       "4       NaN       NaN  C       NaN        NaN       NaN       NaN       NaN   \n",
       "\n",
       "          v9       v10    ...         v122      v123      v124  v125  \\\n",
       "0   9.999999  0.503281    ...     8.000000  1.989780  0.035754    AU   \n",
       "1        NaN  1.312910    ...          NaN       NaN  0.598896    AF   \n",
       "2  12.666667  0.765864    ...     9.333333  2.477596  0.013452    AE   \n",
       "3   8.965516  6.542669    ...     7.018256  1.812795  0.002267    CJ   \n",
       "4        NaN  1.050328    ...          NaN       NaN       NaN     Z   \n",
       "\n",
       "       v126      v127      v128  v129      v130      v131  \n",
       "0  1.804126  3.113719  2.024285     0  0.636365  2.857144  \n",
       "1       NaN       NaN  1.957825     0       NaN       NaN  \n",
       "2  1.773709  3.922193  1.120468     2  0.883118  1.176472  \n",
       "3  1.415230  2.954381  1.990847     1  1.677108  1.034483  \n",
       "4       NaN       NaN       NaN     0       NaN       NaN  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr=pd.read_csv('train.csv')\n",
    "te=pd.read_csv('test.csv')\n",
    "\n",
    "target = tr['target']\n",
    "tr = tr.drop(['ID','target'],axis=1)\n",
    "IDs = te['ID'].values\n",
    "te = te.drop(['ID'],axis=1)\n",
    "\n",
    "# This seems to be a canonical list of data to avoid...\n",
    "#tr = tr.drop(['v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "#te = te.drop(['v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114321 114393 131\n",
      "Training set with full rows size: (64519, 131)\n",
      "Training set with NaN rows size: (49802, 50)\n",
      "Test set with full rows size: (64544, 131)\n",
      "Test set with NaN rows size: (49849, 50)\n"
     ]
    }
   ],
   "source": [
    "# Some basic parameters that we'll use a lot\n",
    "n_tr = tr.shape[0]\n",
    "n_te = te.shape[0]\n",
    "n_keys = tr.shape[1]\n",
    "print n_tr, n_te, n_keys\n",
    "\n",
    "# Some basic settings that we'll use a lot\n",
    "predictor_freq_min_ratio = 10\n",
    "predictor_unique_min_ratio = 20\n",
    "use_dummies = True\n",
    "use_random_imputation = False\n",
    "\n",
    "show_histogram = True\n",
    "\n",
    "skew_z_thresh = 100.0 # Arbitrary choice, looks legit from histograms\n",
    "\n",
    "log_trans = False\n",
    "log_trans_marginals = True\n",
    "log_trans_shift = 1.0e-6\n",
    "\n",
    "tr_full, tr_null, tr_full_row, tr_null_row = split_by_nulls(tr)\n",
    "te_full, te_null, te_full_row, te_null_row = split_by_nulls(te)\n",
    "\n",
    "print \"Training set with full rows size:\", tr_full.shape\n",
    "print \"Training set with NaN rows size:\", tr_null.shape\n",
    "print \"Test set with full rows size:\", te_full.shape\n",
    "print \"Test set with NaN rows size:\", te_null.shape\n",
    "\n",
    "#print tr_full.head()\n",
    "#print tr_null.head()\n",
    "\n",
    "# We replace tr and te so the rest of the workbook works out...\n",
    "tr = tr_full\n",
    "te = te_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "## First we look at distributions (before imputing phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if show_histogram:\n",
    "    pd.set_option('display.mpl_style', 'default') # Make the graphs a bit prettier\n",
    "    pd.DataFrame.hist(tr.join(np.log(tr.select_dtypes(exclude=[object])[tr > 1.0e-5]), lsuffix=\"_n\", rsuffix=\"_log\"),\n",
    "                      figsize=[30,140], layout=[40,6], bins=40)\n",
    "\n",
    "removable_predictors = []\n",
    "skewed_predictors = []\n",
    "\n",
    "for (tr_col_name, tr_col), (te_col_name, te_col) in zip(tr.select_dtypes(exclude=[object]).iteritems(),\\\n",
    "                                                        te.select_dtypes(exclude=[object]).iteritems()):\n",
    "    if te_col_name != tr_col_name:\n",
    "        print \"Uh oh, mismatched columns\", tr_col_name, te_col_name\n",
    "        \n",
    "    # We add columns to a list of \"removables\" if there is too large a ratio between the two most common elements\n",
    "    tr_val_counts = tr_col.value_counts().ravel()\n",
    "    te_val_counts = te_col.value_counts().ravel()\n",
    "    if len(tr_col.unique()) > 2:\n",
    "        if tr_val_counts[0] / tr_val_counts[1] > predictor_freq_min_ratio and float(n_tr) / float(len(tr_col.unique())) > predictor_unique_min_ratio \\\n",
    "           and te_val_counts[0] / te_val_counts[1] > predictor_freq_min_ratio and float(n_te) / float(len(te_col.unique())) > predictor_unique_min_ratio:\n",
    "            # The most frequent value is vastly more frequent than the next, in both the training and testing set\n",
    "            removable_predictors.append(tr_col_name)\n",
    "            print \"Removable predictor? Three training set most common elements:\\n\", tr_col.value_counts()[tr_col.value_counts().keys()[:3]]\n",
    "\n",
    "    # We add columns to a list of \"skewed\" data\n",
    "    [z,p] = sp.stats.skewtest(tr_col.dropna().ravel())\n",
    "    if z > skew_z_thresh:\n",
    "        skewed_predictors.append(tr_col_name)\n",
    "    \n",
    "#\n",
    "    \n",
    "print removable_predictors\n",
    "print skewed_predictors\n",
    "\n",
    "# These \"log-transformable\" predictors are chosen simply from inspecting the histograms below...\n",
    "log_transform = ['v97', 'v95', 'v94', 'v92', 'v8', 'v88', 'v86', 'v85', 'v84', 'v83', 'v76', 'v73',\n",
    "                 'v60', 'v55', 'v50', 'v46', 'v39', 'v33', 'v32', 'v25', 'v23', 'v1', 'v19', 'v18', \n",
    "                 'v17', 'v15', 'v13', 'v131', 'v130', 'v128', 'v127','v126', 'v124', 'v123', 'v121', \n",
    "                 'v120', 'v119', 'v111', 'v109', 'v105', 'v102']\n",
    "marginal_logs = ['v89', 'v63', 'v54', 'v27', 'v26', 'v118', 'v104']\n",
    "\n",
    "if log_trans:\n",
    "    # Then transform all those columns we just listed\n",
    "    # Note that we could use:\n",
    "    # from scipy.stats import boxcar\n",
    "    # BoxCox_Transformed_Data = boxcox(OriginalData)\n",
    "    # and also see: http://shahramabyari.com/2015/12/21/data-preparation-for-predictive-modeling-resolving-skewness/\n",
    "    \n",
    "    for col in log_transform:\n",
    "        if col in tr.keys():\n",
    "            tr[col] = np.log(tr[col]+log_trans_shift)\n",
    "            te[col] = np.log(te[col]+log_trans_shift)\n",
    "        \n",
    "    if log_trans_marginals:\n",
    "        for col in marginal_logs:\n",
    "            if col in tr.keys():\n",
    "                tr[col] = np.log(tr[col]+log_trans_shift)\n",
    "                te[col] = np.log(te[col]+log_trans_shift)\n",
    "                \n",
    "                \n",
    "\n",
    "for (tr_col_name, tr_col), (te_col_name, te_col) in zip(tr.iteritems(),te.iteritems()):\n",
    "    if tr_col.dtype == 'object':\n",
    "        tr_u = tr_col.unique()\n",
    "        te_u = te_col.unique()\n",
    "        if all([u not in te_u for u in tr_u]):\n",
    "            print tr_col.unique()\n",
    "            print te_col.unique()\n",
    "        else:\n",
    "            print tr_col_name, \"has same unique values in both\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling for 30 NaNs in data v1\n",
      "Filling for 0 NaNs in data v2\n",
      "Filling for 2773 NaNs in object data v3\n",
      "Adding 4 dummies for v3\n",
      "Filling for 0 NaNs in data v4\n",
      "Filling for 879 NaNs in data v5\n",
      "Filling for 30 NaNs in data v6\n",
      "Filling for 30 NaNs in data v7\n",
      "Filling for 874 NaNs in data v8\n",
      "Filling for 49 NaNs in data v9\n",
      "Filling for 14 NaNs in data v10\n",
      "Filling for 34 NaNs in data v11\n",
      "Filling for 14 NaNs in data v12\n",
      "Filling for 30 NaNs in data v13\n",
      "Filling for 1 NaNs in data v14\n",
      "Filling for 34 NaNs in data v15\n",
      "Filling for 93 NaNs in data v16\n",
      "Filling for 0 NaNs in data v17\n",
      "Filling for 30 NaNs in data v18\n",
      "Filling for 41 NaNs in data v19\n",
      "Filling for 38 NaNs in data v20\n",
      "Filling for 324 NaNs in data v21\n",
      "Filling for 230 NaNs in object data v22\n",
      "Numerising v22\n",
      "Filling for 879 NaNs in data v23\n",
      "Adding 5 dummies for v24\n",
      "Filling for 874 NaNs in data v25\n",
      "Filling for 30 NaNs in data v26\n",
      "Filling for 30 NaNs in data v27\n",
      "Filling for 30 NaNs in data v28\n",
      "Filling for 30 NaNs in data v29\n",
      "Filling for 23837 NaNs in object data v30\n",
      "Adding 8 dummies for v30\n",
      "Filling for 2773 NaNs in object data v31\n",
      "Adding 4 dummies for v31\n",
      "Filling for 30 NaNs in data v32\n",
      "Filling for 30 NaNs in data v33\n",
      "Filling for 14 NaNs in data v34\n",
      "Filling for 30 NaNs in data v35\n",
      "Filling for 879 NaNs in data v36\n",
      "Filling for 41 NaNs in data v37\n",
      "Filling for 0 NaNs in data v38\n",
      "Filling for 34 NaNs in data v39\n",
      "Filling for 14 NaNs in data v40\n",
      "Filling for 30 NaNs in data v41\n",
      "Filling for 30 NaNs in data v42\n",
      "Filling for 34 NaNs in data v43\n",
      "Filling for 0 NaNs in data v44\n",
      "Filling for 30 NaNs in data v45\n",
      "Filling for 874 NaNs in data v46\n",
      "Adding 9 dummies for v47\n",
      "Filling for 0 NaNs in data v48\n",
      "Filling for 30 NaNs in data v49\n",
      "Filling for 14 NaNs in data v50\n",
      "Filling for 882 NaNs in data v51\n",
      "Adding 12 dummies for v52\n",
      "Filling for 34 NaNs in data v53\n",
      "Filling for 874 NaNs in data v54\n",
      "Filling for 30 NaNs in data v55\n",
      "Filling for 3577 NaNs in object data v56\n",
      "Numerising v56\n",
      "Filling for 30 NaNs in data v57\n",
      "Filling for 34 NaNs in data v58\n",
      "Filling for 0 NaNs in data v59\n",
      "Filling for 30 NaNs in data v60\n",
      "Filling for 0 NaNs in data v61\n",
      "Filling for 0 NaNs in data v62\n",
      "Filling for 874 NaNs in data v63\n",
      "Filling for 0 NaNs in data v64\n",
      "Filling for 38 NaNs in data v65\n",
      "Adding 3 dummies for v66\n",
      "Filling for 30 NaNs in data v67\n",
      "Filling for 34 NaNs in data v68\n",
      "Filling for 93 NaNs in data v69\n",
      "Filling for 891 NaNs in data v70\n",
      "Adding 6 dummies for v71\n",
      "Filling for 0 NaNs in data v72\n",
      "Filling for 34 NaNs in data v73\n",
      "Adding 3 dummies for v74\n",
      "Adding 3 dummies for v75\n",
      "Filling for 0 NaNs in data v76\n",
      "Filling for 30 NaNs in data v77\n",
      "Filling for 93 NaNs in data v78\n",
      "Adding 17 dummies for v79\n",
      "Filling for 49 NaNs in data v80\n",
      "Filling for 879 NaNs in data v81\n",
      "Filling for 879 NaNs in data v82\n",
      "Filling for 30 NaNs in data v83\n",
      "Filling for 30 NaNs in data v84\n",
      "Filling for 886 NaNs in data v85\n",
      "Filling for 30 NaNs in data v86\n",
      "Filling for 918 NaNs in data v87\n",
      "Filling for 30 NaNs in data v88\n",
      "Filling for 874 NaNs in data v89\n",
      "Filling for 34 NaNs in data v90\n",
      "Adding 7 dummies for v91\n",
      "Filling for 41 NaNs in data v92\n",
      "Filling for 30 NaNs in data v93\n",
      "Filling for 30 NaNs in data v94\n",
      "Filling for 41 NaNs in data v95\n",
      "Filling for 30 NaNs in data v96\n",
      "Filling for 41 NaNs in data v97\n",
      "Filling for 909 NaNs in data v98\n",
      "Filling for 30 NaNs in data v99\n",
      "Filling for 34 NaNs in data v100\n",
      "Filling for 0 NaNs in data v101\n",
      "Filling for 1520 NaNs in data v102\n",
      "Filling for 30 NaNs in data v103\n",
      "Filling for 30 NaNs in data v104\n",
      "Filling for 913 NaNs in data v105\n",
      "Filling for 0 NaNs in data v106\n",
      "Adding 7 dummies for v107\n",
      "Filling for 879 NaNs in data v108\n",
      "Filling for 879 NaNs in data v109\n",
      "Adding 3 dummies for v110\n",
      "Filling for 30 NaNs in data v111\n",
      "Filling for 66 NaNs in object data v112\n",
      "Adding 23 dummies for v112\n",
      "Filling for 33777 NaNs in object data v113\n",
      "Adding 35 dummies for v113\n",
      "Filling for 0 NaNs in data v114\n",
      "Filling for 93 NaNs in data v115\n",
      "Filling for 34 NaNs in data v116\n",
      "Filling for 879 NaNs in data v117\n",
      "Filling for 41 NaNs in data v118\n",
      "Filling for 884 NaNs in data v119\n",
      "Filling for 34 NaNs in data v120\n",
      "Filling for 38 NaNs in data v121\n",
      "Filling for 49 NaNs in data v122\n",
      "Filling for 882 NaNs in data v123\n",
      "Filling for 874 NaNs in data v124\n",
      "Filling for 16 NaNs in object data v125\n",
      "Adding 90 dummies for v125\n",
      "Filling for 30 NaNs in data v126\n",
      "Filling for 30 NaNs in data v127\n",
      "Filling for 879 NaNs in data v128\n",
      "Filling for 0 NaNs in data v129\n",
      "Filling for 41 NaNs in data v130\n",
      "Filling for 93 NaNs in data v131\n",
      "Filling for 30 NaNs in data v1\n",
      "Filling for 0 NaNs in data v2\n",
      "Filling for 2773 NaNs in object data v3\n",
      "Adding 4 dummies for v3\n",
      "Filling for 0 NaNs in data v4\n",
      "Filling for 872 NaNs in data v5\n",
      "Filling for 30 NaNs in data v6\n",
      "Filling for 30 NaNs in data v7\n",
      "Filling for 866 NaNs in data v8\n",
      "Filling for 37 NaNs in data v9\n",
      "Filling for 19 NaNs in data v10\n",
      "Filling for 32 NaNs in data v11\n",
      "Filling for 19 NaNs in data v12\n",
      "Filling for 30 NaNs in data v13\n",
      "Filling for 2 NaNs in data v14\n",
      "Filling for 32 NaNs in data v15\n",
      "Filling for 95 NaNs in data v16\n",
      "Filling for 0 NaNs in data v17\n",
      "Filling for 30 NaNs in data v18\n",
      "Filling for 38 NaNs in data v19\n",
      "Filling for 33 NaNs in data v20\n",
      "Filling for 316 NaNs in data v21\n",
      "Filling for 221 NaNs in object data v22\n",
      "Numerising v22\n",
      "Filling for 873 NaNs in data v23\n",
      "Adding 5 dummies for v24\n",
      "Filling for 866 NaNs in data v25\n",
      "Filling for 30 NaNs in data v26\n",
      "Filling for 30 NaNs in data v27\n",
      "Filling for 30 NaNs in data v28\n",
      "Filling for 30 NaNs in data v29\n",
      "Filling for 24097 NaNs in object data v30\n",
      "Adding 8 dummies for v30\n",
      "Filling for 2773 NaNs in object data v31\n",
      "Adding 4 dummies for v31\n",
      "Filling for 30 NaNs in data v32\n",
      "Filling for 30 NaNs in data v33\n",
      "Filling for 19 NaNs in data v34\n",
      "Filling for 30 NaNs in data v35\n",
      "Filling for 872 NaNs in data v36\n",
      "Filling for 38 NaNs in data v37\n",
      "Filling for 0 NaNs in data v38\n",
      "Filling for 31 NaNs in data v39\n",
      "Filling for 19 NaNs in data v40\n",
      "Filling for 30 NaNs in data v41\n",
      "Filling for 30 NaNs in data v42\n",
      "Filling for 32 NaNs in data v43\n",
      "Filling for 0 NaNs in data v44\n",
      "Filling for 30 NaNs in data v45\n",
      "Filling for 866 NaNs in data v46\n",
      "Adding 9 dummies for v47\n",
      "Filling for 0 NaNs in data v48\n",
      "Filling for 30 NaNs in data v49\n",
      "Filling for 19 NaNs in data v50\n",
      "Filling for 877 NaNs in data v51\n",
      "Adding 12 dummies for v52\n",
      "Filling for 32 NaNs in data v53\n",
      "Filling for 866 NaNs in data v54\n",
      "Filling for 30 NaNs in data v55\n",
      "Filling for 3505 NaNs in object data v56\n",
      "Numerising v56\n",
      "Filling for 30 NaNs in data v57\n",
      "Filling for 31 NaNs in data v58\n",
      "Filling for 0 NaNs in data v59\n",
      "Filling for 30 NaNs in data v60\n",
      "Filling for 0 NaNs in data v61\n",
      "Filling for 0 NaNs in data v62\n",
      "Filling for 866 NaNs in data v63\n",
      "Filling for 0 NaNs in data v64\n",
      "Filling for 33 NaNs in data v65\n",
      "Adding 3 dummies for v66\n",
      "Filling for 30 NaNs in data v67\n",
      "Filling for 31 NaNs in data v68\n",
      "Filling for 95 NaNs in data v69\n",
      "Filling for 877 NaNs in data v70\n",
      "Adding 8 dummies for v71\n",
      "Filling for 0 NaNs in data v72\n",
      "Filling for 32 NaNs in data v73\n",
      "Adding 3 dummies for v74\n",
      "Adding 4 dummies for v75\n",
      "Filling for 0 NaNs in data v76\n",
      "Filling for 30 NaNs in data v77\n",
      "Filling for 95 NaNs in data v78\n",
      "Adding 17 dummies for v79\n",
      "Filling for 37 NaNs in data v80\n",
      "Filling for 872 NaNs in data v81\n",
      "Filling for 872 NaNs in data v82\n",
      "Filling for 30 NaNs in data v83\n",
      "Filling for 30 NaNs in data v84\n",
      "Filling for 877 NaNs in data v85\n",
      "Filling for 30 NaNs in data v86\n",
      "Filling for 901 NaNs in data v87\n",
      "Filling for 30 NaNs in data v88\n",
      "Filling for 866 NaNs in data v89\n",
      "Filling for 33 NaNs in data v90\n",
      "Adding 7 dummies for v91\n",
      "Filling for 38 NaNs in data v92\n",
      "Filling for 30 NaNs in data v93\n",
      "Filling for 30 NaNs in data v94\n",
      "Filling for 38 NaNs in data v95\n",
      "Filling for 30 NaNs in data v96\n",
      "Filling for 38 NaNs in data v97\n",
      "Filling for 903 NaNs in data v98\n",
      "Filling for 30 NaNs in data v99\n",
      "Filling for 31 NaNs in data v100\n",
      "Filling for 0 NaNs in data v101\n",
      "Filling for 1522 NaNs in data v102\n",
      "Filling for 30 NaNs in data v103\n",
      "Filling for 30 NaNs in data v104\n",
      "Filling for 895 NaNs in data v105\n",
      "Filling for 0 NaNs in data v106\n",
      "Adding 7 dummies for v107\n",
      "Filling for 872 NaNs in data v108\n",
      "Filling for 872 NaNs in data v109\n",
      "Adding 3 dummies for v110\n",
      "Filling for 30 NaNs in data v111\n",
      "Filling for 78 NaNs in object data v112\n",
      "Adding 23 dummies for v112\n",
      "Filling for 33752 NaNs in object data v113\n",
      "Adding 36 dummies for v113\n",
      "Filling for 0 NaNs in data v114\n",
      "Filling for 95 NaNs in data v115\n",
      "Filling for 32 NaNs in data v116\n",
      "Filling for 872 NaNs in data v117\n",
      "Filling for 38 NaNs in data v118\n",
      "Filling for 876 NaNs in data v119\n",
      "Filling for 31 NaNs in data v120\n",
      "Filling for 33 NaNs in data v121\n",
      "Filling for 37 NaNs in data v122\n",
      "Filling for 877 NaNs in data v123\n",
      "Filling for 866 NaNs in data v124\n",
      "Filling for 11 NaNs in object data v125\n",
      "Adding 90 dummies for v125\n",
      "Filling for 30 NaNs in data v126\n",
      "Filling for 30 NaNs in data v127\n",
      "Filling for 872 NaNs in data v128\n",
      "Filling for 0 NaNs in data v129\n",
      "Filling for 38 NaNs in data v130\n",
      "Filling for 95 NaNs in data v131\n",
      "Filling for 684 NaNs in object data v3\n",
      "Adding 4 dummies for v3\n",
      "Filling for 47745 NaNs in data v5\n",
      "Filling for 47745 NaNs in data v8\n",
      "Filling for 70 NaNs in data v10\n",
      "Filling for 72 NaNs in data v12\n",
      "Filling for 3 NaNs in data v14\n",
      "Filling for 287 NaNs in data v21\n",
      "Filling for 270 NaNs in object data v22\n",
      "Numerising v22\n",
      "Adding 5 dummies for v24\n",
      "Filling for 47745 NaNs in data v25\n",
      "Filling for 36273 NaNs in object data v30\n",
      "Adding 8 dummies for v30\n",
      "Filling for 684 NaNs in object data v31\n",
      "Adding 4 dummies for v31\n",
      "Filling for 97 NaNs in data v34\n",
      "Filling for 47745 NaNs in data v36\n",
      "Filling for 0 NaNs in data v38\n",
      "Filling for 97 NaNs in data v40\n",
      "Filling for 47745 NaNs in data v46\n",
      "Adding 10 dummies for v47\n",
      "Filling for 72 NaNs in data v50\n",
      "Filling for 3 NaNs in object data v52\n",
      "Adding 13 dummies for v52\n",
      "Filling for 47745 NaNs in data v54\n",
      "Filling for 3305 NaNs in object data v56\n",
      "Numerising v56\n",
      "Filling for 0 NaNs in data v62\n",
      "Filling for 47745 NaNs in data v63\n",
      "Adding 3 dummies for v66\n",
      "Filling for 47745 NaNs in data v70\n",
      "Adding 7 dummies for v71\n",
      "Filling for 0 NaNs in data v72\n",
      "Adding 3 dummies for v74\n",
      "Adding 4 dummies for v75\n",
      "Adding 18 dummies for v79\n",
      "Filling for 47745 NaNs in data v81\n",
      "Filling for 47745 NaNs in data v82\n",
      "Filling for 47745 NaNs in data v87\n",
      "Filling for 47745 NaNs in data v89\n",
      "Filling for 3 NaNs in object data v91\n",
      "Adding 8 dummies for v91\n",
      "Filling for 47745 NaNs in data v98\n",
      "Filling for 47745 NaNs in data v105\n",
      "Filling for 3 NaNs in object data v107\n",
      "Adding 8 dummies for v107\n",
      "Filling for 47745 NaNs in data v108\n",
      "Filling for 47745 NaNs in data v109\n",
      "Adding 3 dummies for v110\n",
      "Filling for 316 NaNs in object data v112\n",
      "Adding 23 dummies for v112\n",
      "Filling for 21527 NaNs in object data v113\n",
      "Adding 37 dummies for v113\n",
      "Filling for 30 NaNs in data v114\n",
      "Filling for 47745 NaNs in data v117\n",
      "Filling for 47745 NaNs in data v124\n",
      "Filling for 61 NaNs in object data v125\n",
      "Adding 91 dummies for v125\n",
      "Filling for 47745 NaNs in data v128\n",
      "Filling for 0 NaNs in data v129\n",
      "Filling for 719 NaNs in object data v3\n",
      "Adding 4 dummies for v3\n",
      "Filling for 47770 NaNs in data v5\n",
      "Filling for 47770 NaNs in data v8\n",
      "Filling for 63 NaNs in data v10\n",
      "Filling for 65 NaNs in data v12\n",
      "Filling for 0 NaNs in data v14\n",
      "Filling for 257 NaNs in data v21\n",
      "Filling for 256 NaNs in object data v22\n",
      "Numerising v22\n",
      "Adding 5 dummies for v24\n",
      "Filling for 47770 NaNs in data v25\n",
      "Filling for 36245 NaNs in object data v30\n",
      "Adding 8 dummies for v30\n",
      "Filling for 719 NaNs in object data v31\n",
      "Adding 4 dummies for v31\n",
      "Filling for 85 NaNs in data v34\n",
      "Filling for 47770 NaNs in data v36\n",
      "Filling for 0 NaNs in data v38\n",
      "Filling for 85 NaNs in data v40\n",
      "Filling for 47770 NaNs in data v46\n",
      "Adding 9 dummies for v47\n",
      "Filling for 65 NaNs in data v50\n",
      "Filling for 2 NaNs in object data v52\n",
      "Adding 13 dummies for v52\n",
      "Filling for 47770 NaNs in data v54\n",
      "Filling for 3413 NaNs in object data v56\n",
      "Numerising v56\n",
      "Filling for 0 NaNs in data v62\n",
      "Filling for 47770 NaNs in data v63\n",
      "Adding 3 dummies for v66\n",
      "Filling for 47770 NaNs in data v70\n",
      "Adding 5 dummies for v71\n",
      "Filling for 0 NaNs in data v72\n",
      "Adding 3 dummies for v74\n",
      "Adding 4 dummies for v75\n",
      "Adding 16 dummies for v79\n",
      "Filling for 47770 NaNs in data v81\n",
      "Filling for 47770 NaNs in data v82\n",
      "Filling for 47770 NaNs in data v87\n",
      "Filling for 47770 NaNs in data v89\n",
      "Filling for 2 NaNs in object data v91\n",
      "Adding 8 dummies for v91\n",
      "Filling for 47770 NaNs in data v98\n",
      "Filling for 47770 NaNs in data v105\n",
      "Filling for 2 NaNs in object data v107\n",
      "Adding 8 dummies for v107\n",
      "Filling for 47770 NaNs in data v108\n",
      "Filling for 47770 NaNs in data v109\n",
      "Adding 3 dummies for v110\n",
      "Filling for 335 NaNs in object data v112\n",
      "Adding 23 dummies for v112\n",
      "Filling for 21606 NaNs in object data v113\n",
      "Adding 37 dummies for v113\n",
      "Filling for 24 NaNs in data v114\n",
      "Filling for 47770 NaNs in data v117\n",
      "Filling for 47770 NaNs in data v124\n",
      "Filling for 73 NaNs in object data v125\n",
      "Adding 91 dummies for v125\n",
      "Filling for 47770 NaNs in data v128\n",
      "Filling for 0 NaNs in data v129\n"
     ]
    }
   ],
   "source": [
    "# Find all the columns with string data\n",
    "tr = randomised_imputer(tr)\n",
    "te = randomised_imputer(te)\n",
    "tr_null = randomised_imputer(tr_null)\n",
    "te_null = randomised_imputer(te_null)\n",
    "\n",
    "#imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "#imp.fit(tr)\n",
    "#imp.transform(tr)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgtr = xgb.DMatrix(tr.values, target.ix[tr_full_row].values)\n",
    "xgte = xgb.DMatrix(te.values)\n",
    "xgtr_null = xgb.DMatrix(tr_null.values, target.ix[tr_null_row].values)\n",
    "xgte_null = xgb.DMatrix(te_null.values)\n",
    "\n",
    "params = {'objective': 'binary:logistic', \n",
    "          'subsample': 1, \n",
    "          'eta': 0.1,                    # eta : step size shrinkage on each boosting step\n",
    "          #'gamma': 0.0,                 # minimum loss reduction requireed to make a further partition\n",
    "          #'lambda': 1.0,                # L2 regularization term on weights\n",
    "          #'alpha': 0.0,                 # L1 regularization term on weights\n",
    "          'colsample_bytree': 0.9,       # subsample ratio of columns when constructing each tree\n",
    "          'max_depth': 10,               # maximum depth of a single tree, default = 6\n",
    "          'min_child_weight' : 5,        # minimum sum of weight needed in a child, default = 1\n",
    "          'silent': 0 }\n",
    "\n",
    "boost_round = 50\n",
    "#clf = xgb.cv(params, xgtr, num_boost_round=num_round, metrics={'logloss'}, nfold=5,\n",
    "#             seed=0, maximize=False)\n",
    "\n",
    "clf = xgb.train(params, xgtr, num_boost_round=boost_round, verbose_eval=True, maximize=False)\n",
    "clf_null = xgb.train(params, xgtr_full, num_boost_round=boost_round, verbose_eval=True, maximize=False)\n",
    "\n",
    "# Make predictions\n",
    "print('Predict...')\n",
    "te_pred_full = clf.predict(xgte, ntree_limit=clf.best_iteration)\n",
    "te_pred_null = clf.predict(xgte_null, ntree_limit=clf.best_iteration)\n",
    "te_pred = pd.concat([te_pred_full, te_pred_null])\n",
    "pdb.set_trace()\n",
    "# Save results\n",
    "predictions_file = open(\"simple_xgboost_result.csv\", \"w\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"ID\", \"PredictedProb\"])\n",
    "\n",
    "open_file_object.writerows(zip(IDs, te_pred))\n",
    "predictions_file.close()\n",
    "#\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tr.keys()\n",
    "#print tr_keys_orig\n",
    "\n",
    "#[tr_fac, tr_lab] = pd.factorize(tr['v22'])\n",
    "#tr['v22'] = tr_fac\n",
    "#tr['v56'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing out some techniques on dataframes\n",
    "n = 10\n",
    "choices = range(n/2)\n",
    "df = pd.DataFrame({'a': np.random.normal(0,1,n), 'b' : np.random.choice(choices,n)})\n",
    "print df\n",
    "print df['b'].unique()\n",
    "print np.bincount(df['b'])\n",
    "print np.float32(np.bincount(df['b'])) /len(df['b'])\n",
    "print np.float32(df['b'].value_counts().ravel()) / len(df['b'])\n",
    "\n",
    "np.random.choice(df['b'].value_counts().keys().ravel(), size=3,\n",
    "                             p = np.float32(df['b'].value_counts().ravel()) / df['b'].value_counts().ravel().sum() )\n",
    "\n",
    "#unique_values = np.sort(tr.ix[:,i].unique())    \n",
    "#if unique_values.dtype in [np.int64, np.float64]:\n",
    "#    field_hist, field_bins = np.histogram(tr.ix[:,i], unique_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
